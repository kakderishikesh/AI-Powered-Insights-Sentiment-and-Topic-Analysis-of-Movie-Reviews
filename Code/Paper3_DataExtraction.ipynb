{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction for the Project\n",
    "This notebook extracts the data to be used for the paper 3 titled: 'Most popular Topics in Positive and Negative Sentiments in Amazon Movies and TV Reviews Dataset'\n",
    "#### Author: Rishikesh Kakde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from empath import Empath\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Movies_and_TV.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of entries: 17328314\n"
     ]
    }
   ],
   "source": [
    "# Count the number of lines in the file\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    total_entries = sum(1 for line in f)\n",
    "\n",
    "print(f\"Total number of entries: {total_entries}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis dataset size: 1500\n",
      "Training dataset size: 2000\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to hold the analysis and training datasets\n",
    "analysis_data = []\n",
    "training_data = []\n",
    "\n",
    "# Open the JSONL file and process the first 3500 rows\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        data = json.loads(line)\n",
    "        if i < 1500:  # First 1500 rows for analysis dataset\n",
    "            analysis_data.append(data)\n",
    "        elif 1500 <= i < 3500:  # Next 2000 rows for training dataset\n",
    "            training_data.append(data)\n",
    "        elif i >= 3500:  # Stop processing after 3500 rows\n",
    "            break\n",
    "\n",
    "# Print the size of each dataset\n",
    "print(f\"Analysis dataset size: {len(analysis_data)}\")\n",
    "print(f\"Training dataset size: {len(training_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the Analysis Dataset to a DataFrame and Export as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis dataset saved as 'analysis_dataset.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Convert the analysis dataset to a pandas DataFrame\n",
    "analysis_df = pd.DataFrame(analysis_data)\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "analysis_df.to_csv('analysis_dataset.csv', index=False)\n",
    "\n",
    "# Confirm the file has been saved\n",
    "print(\"Analysis dataset saved as 'analysis_dataset.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Training Dataset to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in training dataset: Index(['rating', 'title', 'text', 'images', 'asin', 'parent_asin', 'user_id',\n",
      "       'timestamp', 'helpful_vote', 'verified_purchase'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>images</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>One Star</td>\n",
       "      <td>The Kids wanted it and watched.  I thought it ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B006QKJQ12</td>\n",
       "      <td>B006QKJQ12</td>\n",
       "      <td>AHRM6YFXTOLMHK2MZZ7D2W2W2Q6Q</td>\n",
       "      <td>1453930439000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Sharknado</td>\n",
       "      <td>My 7 year old grandson had me watch this.  It ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B00EY74PJM</td>\n",
       "      <td>B00EY74PJM</td>\n",
       "      <td>AHRM6YFXTOLMHK2MZZ7D2W2W2Q6Q</td>\n",
       "      <td>1402404892000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Flight</td>\n",
       "      <td>Very good movie and enjoyed it very much.  I l...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B00B0LPWU6</td>\n",
       "      <td>B00B0LPWU6</td>\n",
       "      <td>AHRM6YFXTOLMHK2MZZ7D2W2W2Q6Q</td>\n",
       "      <td>1398870334000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Downton Abbey Season 1</td>\n",
       "      <td>Great series, loved it.  Very easy to get righ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B004KAJLNS</td>\n",
       "      <td>B004KAJLNS</td>\n",
       "      <td>AHRM6YFXTOLMHK2MZZ7D2W2W2Q6Q</td>\n",
       "      <td>1397309345000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Excellent Movie!!!</td>\n",
       "      <td>This film has become my favorite movie. Denzel...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B00UGQAB4S</td>\n",
       "      <td>B00UGQAB4S</td>\n",
       "      <td>AHU2Y2ZFQKI3V3ARFDKZA6ER4NUQ</td>\n",
       "      <td>1566075686049</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                   title  \\\n",
       "0     1.0                One Star   \n",
       "1     3.0               Sharknado   \n",
       "2     5.0                  Flight   \n",
       "3     5.0  Downton Abbey Season 1   \n",
       "4     5.0      Excellent Movie!!!   \n",
       "\n",
       "                                                text images        asin  \\\n",
       "0  The Kids wanted it and watched.  I thought it ...     []  B006QKJQ12   \n",
       "1  My 7 year old grandson had me watch this.  It ...     []  B00EY74PJM   \n",
       "2  Very good movie and enjoyed it very much.  I l...     []  B00B0LPWU6   \n",
       "3  Great series, loved it.  Very easy to get righ...     []  B004KAJLNS   \n",
       "4  This film has become my favorite movie. Denzel...     []  B00UGQAB4S   \n",
       "\n",
       "  parent_asin                       user_id      timestamp  helpful_vote  \\\n",
       "0  B006QKJQ12  AHRM6YFXTOLMHK2MZZ7D2W2W2Q6Q  1453930439000             0   \n",
       "1  B00EY74PJM  AHRM6YFXTOLMHK2MZZ7D2W2W2Q6Q  1402404892000             1   \n",
       "2  B00B0LPWU6  AHRM6YFXTOLMHK2MZZ7D2W2W2Q6Q  1398870334000             0   \n",
       "3  B004KAJLNS  AHRM6YFXTOLMHK2MZZ7D2W2W2Q6Q  1397309345000             0   \n",
       "4  B00UGQAB4S  AHU2Y2ZFQKI3V3ARFDKZA6ER4NUQ  1566075686049             2   \n",
       "\n",
       "   verified_purchase  \n",
       "0               True  \n",
       "1              False  \n",
       "2              False  \n",
       "3              False  \n",
       "4               True  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = pd.DataFrame(training_data)\n",
    "\n",
    "# Display the first few rows to identify unnecessary columns\n",
    "print(\"Columns in training dataset:\", training_df.columns)\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Unwanted Columns form the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after dropping unnecessary ones: Index(['rating', 'text', 'timestamp'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Specify the columns to drop\n",
    "columns_to_drop = ['title', 'images', 'asin', 'parent_asin', 'user_id', 'helpful_vote', 'verified_purchase']\n",
    "\n",
    "# Drop the specified columns\n",
    "training_df = training_df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Display the remaining columns\n",
    "print(\"Columns after dropping unnecessary ones:\", training_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Training Data Using EMPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "neutral     1277\n",
      "positive     567\n",
      "negative     156\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Empath tool\n",
    "lexicon = Empath()\n",
    "\n",
    "# Function to classify sentiment based on the review text\n",
    "def assign_sentiment(text):\n",
    "    if not text:\n",
    "        return None  # Handle empty or missing text\n",
    "    analysis = lexicon.analyze(text, categories=['positive_emotion', 'negative_emotion'])\n",
    "    positive_score = analysis.get('positive_emotion', 0)\n",
    "    negative_score = analysis.get('negative_emotion', 0)\n",
    "    \n",
    "    if positive_score > negative_score:\n",
    "        return 'positive'\n",
    "    elif negative_score > positive_score:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Apply the function to the review column (adjust 'reviewText' to the correct column name)\n",
    "training_df['sentiment'] = training_df['text'].apply(assign_sentiment)\n",
    "\n",
    "# Drop rows where sentiment could not be assigned\n",
    "training_df = training_df.dropna(subset=['sentiment'])\n",
    "\n",
    "# Display the sentiment distribution\n",
    "print(training_df['sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Export the Labeled Training Dataset as CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled training dataset saved as 'training_dataset_labeled.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Export the labeled training dataset to a CSV file\n",
    "training_df.to_csv('training_dataset_labeled.csv', index=False)\n",
    "\n",
    "# Confirm the file has been saved\n",
    "print(\"Labeled training dataset saved as 'training_dataset_labeled.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

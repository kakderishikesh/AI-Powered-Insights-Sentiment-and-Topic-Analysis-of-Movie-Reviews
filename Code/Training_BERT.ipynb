{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training (Fine-tuning) BERT on the dataset\n",
    "This notebook extracts the data to be used for the paper 3 titled: 'Most popular Topics in Positive and Negative Sentiments in Amazon Movies and TV Reviews Dataset'\n",
    "#### Author: Rishikesh Kakde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exouser/Downloads/SMM/env_smm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import Dataset as HFDataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Print the selected device\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Labeled Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Preview:\n",
      "   rating                                               text      timestamp  \\\n",
      "0     1.0  The Kids wanted it and watched.  I thought it ...  1453930439000   \n",
      "1     3.0  My 7 year old grandson had me watch this.  It ...  1402404892000   \n",
      "2     5.0  Very good movie and enjoyed it very much.  I l...  1398870334000   \n",
      "3     5.0  Great series, loved it.  Very easy to get righ...  1397309345000   \n",
      "4     5.0  This film has become my favorite movie. Denzel...  1566075686049   \n",
      "\n",
      "  sentiment  \n",
      "0  negative  \n",
      "1   neutral  \n",
      "2  positive  \n",
      "3  positive  \n",
      "4   neutral  \n",
      "Sentiment Distribution:\n",
      "sentiment\n",
      "neutral     1277\n",
      "positive     567\n",
      "negative     156\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the labeled dataset\n",
    "training_data_path = \"training_dataset_labeled.csv\"\n",
    "df = pd.read_csv(training_data_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Training Data Preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check class distribution\n",
    "print(\"Sentiment Distribution:\")\n",
    "print(df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map Sentiments to Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the sentiments to numeric labels for training\n",
    "sentiment_mapping = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "df['label'] = df['sentiment'].map(sentiment_mapping)\n",
    "\n",
    "# Ensure the 'text' and 'label' columns are present\n",
    "df = df[['text', 'label']].dropna()\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['text'].tolist(), df['label'].tolist(), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Text Data Using BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the data\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]).to(device) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx]).to(device)\n",
    "        return item\n",
    "\n",
    "    \n",
    "# Create the datasets\n",
    "train_dataset = SentimentDataset(train_encodings, train_labels)\n",
    "val_dataset = SentimentDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Pre-Trained BERT Model for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-trained BERT model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "\n",
    "# Move the model to the GPU\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Up Training Arguments and Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,  \n",
    "    per_device_eval_batch_size=8,  \n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "# Create a data collator to handle padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         # The pre-trained BERT model\n",
    "    args=training_args,                  # Training arguments\n",
    "    train_dataset=train_dataset,         # Training dataset\n",
    "    eval_dataset=val_dataset,            # Validation dataset\n",
    "    tokenizer=tokenizer,                 # Tokenizer\n",
    "    data_collator=data_collator          # Data collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1200/1200 02:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.766600</td>\n",
       "      <td>0.586901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.492879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.531300</td>\n",
       "      <td>0.474424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./sentiment_model/tokenizer_config.json',\n",
       " './sentiment_model/special_tokens_map.json',\n",
       " './sentiment_model/vocab.txt',\n",
       " './sentiment_model/added_tokens.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune the model on the training dataset\n",
    "trainer.train()\n",
    "\n",
    "# Save the trained model\n",
    "trainer.save_model(\"./sentiment_model\")\n",
    "tokenizer.save_pretrained(\"./sentiment_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Analysis Dataset and Perform Sentiment Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis dataset with sentiments saved as 'analysis_dataset_with_sentiments.csv'.\n"
     ]
    }
   ],
   "source": [
    "# ## Step 1: Load the Analysis Dataset\n",
    "analysis_data_path = \"analysis_dataset.csv\"\n",
    "analysis_df = pd.read_csv(analysis_data_path)\n",
    "\n",
    "# ## Step 2: Set Up Batch Processing\n",
    "batch_size = 32  # Process in batches of 32\n",
    "analysis_texts = analysis_df['text'].tolist()\n",
    "num_batches = len(analysis_texts) // batch_size + 1\n",
    "\n",
    "# ## Step 3: Prepare Sentiment Mapping and Model for Prediction\n",
    "# Reverse mapping for sentiment labels\n",
    "reverse_sentiment_mapping = {v: k for k, v in sentiment_mapping.items()}\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# ## Step 4: Predict Sentiments in Batches\n",
    "predictions = []\n",
    "for i in range(num_batches):\n",
    "    # Extract batch texts\n",
    "    batch_texts = analysis_texts[i * batch_size : (i + 1) * batch_size]\n",
    "    \n",
    "    # Tokenize and move to GPU\n",
    "    encodings = tokenizer(batch_texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "    encodings = {key: val.to(device) for key, val in encodings.items()}\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encodings)\n",
    "        batch_predictions = torch.argmax(outputs.logits, dim=1).cpu().tolist()\n",
    "        predictions.extend(batch_predictions)\n",
    "\n",
    "# ## Step 5: Map Predictions Back to Sentiment Labels\n",
    "analysis_df['predicted_sentiment'] = [reverse_sentiment_mapping[pred] for pred in predictions]\n",
    "\n",
    "# ## Step 6: Save Results to CSV\n",
    "analysis_df.to_csv('analysis_dataset_with_sentiments.csv', index=False)\n",
    "print(\"Analysis dataset with sentiments saved as 'analysis_dataset_with_sentiments.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rating', 'title', 'text', 'images', 'asin', 'parent_asin', 'user_id',\n",
       "       'timestamp', 'helpful_vote', 'verified_purchase',\n",
       "       'predicted_sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison with EMPATH Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis Data Preview:\n",
      "   rating                                              title  \\\n",
      "0     5.0                                         Five Stars   \n",
      "1     5.0                                         Five Stars   \n",
      "2     3.0                       Some decent moments...but...   \n",
      "3     4.0  Decent Depiction of Lower-Functioning Autism, ...   \n",
      "4     5.0                                    What Love Is...   \n",
      "\n",
      "                                                text images        asin  \\\n",
      "0           Amazon, please buy the show! I'm hooked!     []  B013488XFS   \n",
      "1                         My Kiddos LOVE this show!!     []  B00CB6VTDS   \n",
      "2  Annabella Sciorra did her character justice wi...     []  B096Z8Z3R6   \n",
      "3  ...there should be more of a range of characte...     []  B09M14D9FZ   \n",
      "4  ...isn't always how you expect it to be, but w...     []  B001H1SVZC   \n",
      "\n",
      "  parent_asin                       user_id      timestamp  helpful_vote  \\\n",
      "0  B013488XFS  AGGZ357AO26RQZVRLGU4D4N52DZQ  1440385637000             0   \n",
      "1  B00CB6VTDS  AGKASBHYZPGTEPO6LWZPVJWB2BVA  1461100610000             0   \n",
      "2  B096Z8Z3R6  AG2L7H23R5LLKDKLBEF2Q3L2MVDA  1646271834582             0   \n",
      "3  B09M14D9FZ  AG2L7H23R5LLKDKLBEF2Q3L2MVDA  1645937761864             1   \n",
      "4  B001H1SVZC  AG2L7H23R5LLKDKLBEF2Q3L2MVDA  1590639227074             0   \n",
      "\n",
      "   verified_purchase  \n",
      "0               True  \n",
      "1               True  \n",
      "2               True  \n",
      "3              False  \n",
      "4               True  \n"
     ]
    }
   ],
   "source": [
    "# ## Step 1: Load the Analysis Dataset\n",
    "# Load the analysis dataset\n",
    "analysis_data_path = \"analysis_dataset.csv\"\n",
    "analysis_df = pd.read_csv(analysis_data_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Analysis Data Preview:\")\n",
    "print(analysis_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Distribution (Empath Ground Truth):\n",
      "ground_truth_sentiment\n",
      "neutral     767\n",
      "positive    520\n",
      "negative    213\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ## Step 2: Classify Reviews Using EMPATH\n",
    "from empath import Empath\n",
    "\n",
    "# Initialize the Empath tool\n",
    "lexicon = Empath()\n",
    "\n",
    "# Function to classify sentiment based on the review text\n",
    "def assign_sentiment_with_empath(text):\n",
    "    if not isinstance(text, str) or len(text.strip()) == 0:\n",
    "        return None  # Handle empty or missing text\n",
    "    analysis = lexicon.analyze(text, categories=['positive_emotion', 'negative_emotion'])\n",
    "    positive_score = analysis.get('positive_emotion', 0)\n",
    "    negative_score = analysis.get('negative_emotion', 0)\n",
    "    \n",
    "    # Determine sentiment based on scores\n",
    "    if positive_score > negative_score:\n",
    "        return 'positive'\n",
    "    elif negative_score > positive_score:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Apply the sentiment analysis function to the 'text' column\n",
    "analysis_df['ground_truth_sentiment'] = analysis_df['text'].apply(assign_sentiment_with_empath)\n",
    "\n",
    "# Drop rows where sentiment could not be assigned\n",
    "analysis_df = analysis_df.dropna(subset=['ground_truth_sentiment'])\n",
    "\n",
    "# Display the sentiment distribution\n",
    "print(\"Sentiment Distribution (Empath Ground Truth):\")\n",
    "print(analysis_df['ground_truth_sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predictions are not available. Run the BERT model to generate 'predicted_sentiment' column.\n"
     ]
    }
   ],
   "source": [
    "# ## Step 4: Compare Model Predictions to Ground Truth\n",
    "# Ensure both ground truth and model predictions exist in the dataset\n",
    "if 'predicted_sentiment' in analysis_df.columns:\n",
    "    # Calculate the accuracy\n",
    "    accuracy = (analysis_df['predicted_sentiment'] == analysis_df['ground_truth_sentiment']).mean()\n",
    "    print(f\"Model Accuracy Compared to EMPATH Ground Truth: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # Display a confusion matrix for detailed analysis\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "    # Generate the confusion matrix\n",
    "    cm = confusion_matrix(analysis_df['ground_truth_sentiment'], analysis_df['predicted_sentiment'], labels=['positive', 'neutral', 'negative'])\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Generate a classification report\n",
    "    report = classification_report(analysis_df['ground_truth_sentiment'], analysis_df['predicted_sentiment'], labels=['positive', 'neutral', 'negative'])\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "else:\n",
    "    print(\"Model predictions are not available. Run the BERT model to generate 'predicted_sentiment' column.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_smm)",
   "language": "python",
   "name": "env_smm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
